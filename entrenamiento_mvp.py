# -*- coding: utf-8 -*-
"""Final_MVP

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/18Fmuj8QhGXW46VrdH0R26IdYaI25iMkg
"""

# pandas / numpy: manipulación de datos
# sklearn: entrenamiento, pipelines y métricas
# joblib: guardar modelos entrenados

import pandas as pd
import numpy as np

from sklearn.model_selection import train_test_split
from sklearn.compose import ColumnTransformer
from sklearn.preprocessing import OneHotEncoder
from sklearn.pipeline import Pipeline
from sklearn.linear_model import LogisticRegression
from sklearn.metrics import classification_report, roc_auc_score

import joblib

# Dataset generado en la fase anterior (vuelos + clima)

df = pd.read_csv("dataset_vuelos_clima_final (2).csv")

print(df.shape)
df.head()

# Definimos las columnas mínimas necesarias
# Si alguna falta, esa fila no sirve para ML

required_cols = [
    "hour",
    "distance",
    "marketing_airline_network",
    "temp_mean",
    "precipitation",
    "wind_speed",
    "delayed"
]

# Eliminamos filas con valores nulos en columnas clave

df = df.dropna(subset=required_cols)

# Filtro:
# - horas válidas (0–23)
# - distancias positivas

df = df[df["hour"].between(0, 23)]
df = df[df["distance"] > 0]

# FEATURES: variables predictoras
# TARGET: variable objetivo (retraso sí/no)

FEATURES = [
    "hour",
    "distance",
    "marketing_airline_network",
    "temp_mean",
    "precipitation",
    "wind_speed"
]

TARGET = "delayed"

X = df[FEATURES]
y = df[TARGET]

# Necesario para aplicar transformaciones distintas, separamos numericas de categóricas.

numeric_features = [
    "hour",
    "distance",
    "temp_mean",
    "precipitation",
    "wind_speed"
]

categorical_features = [
    "marketing_airline_network"
]

# - Variables numéricas: pasan tal cual
# - Variables categóricas: One-Hot Encoding
# handle_unknown="ignore" evita errores en producción

preprocessor = ColumnTransformer(
    transformers=[
        ("num", "passthrough", numeric_features),
        ("cat", OneHotEncoder(handle_unknown="ignore"), categorical_features)
    ]
)

# Regresión logística:
# 1) Preprocesado
# 2) Modelo de clasificación
# class_weight="balanced":
# corrige desbalanceo de clases (~18% retrasos)

model = Pipeline(steps=[
    ("preprocess", preprocessor),
    ("classifier", LogisticRegression(
        max_iter=1000,
        class_weight="balanced"
    ))
])

# stratify=y mantiene la proporción de retrasos
# random_state asegura reproducibilidad

X_train, X_test, y_train, y_test = train_test_split(
    X,
    y,
    test_size=0.2,
    random_state=42,
    stratify=y
)

model.fit(X_train, y_train)

# evaluamos regresión
# y_pred: clase final
# y_proba: probabilidad de retraso

y_pred = model.predict(X_test)
y_proba = model.predict_proba(X_test)[:, 1]

print("LOGISTIC REGRESSION\n")
print(classification_report(y_test, y_pred))
print("ROC AUC:", roc_auc_score(y_test, y_proba))

# Se guarda el pipeline completo (preprocesado + modelo)

joblib.dump(model, "flight_delay_model.pkl")

from sklearn.ensemble import RandomForestClassifier

# Random Forest
# Misma entrada y preprocesado
# Solo cambia el modelo final

rf_model = Pipeline(steps=[
    ("preprocess", preprocessor),
    ("classifier", RandomForestClassifier(
        n_estimators=100,
        max_depth=10,
        random_state=42,
        class_weight="balanced"
    ))
])

rf_model.fit(X_train, y_train)   #entrenamiento

y_pred_rf = rf_model.predict(X_test)                    #evaluacion
y_proba_rf = rf_model.predict_proba(X_test)[:, 1]

print("RANDOM FOREST\n")
print(classification_report(y_test, y_pred_rf))
print("ROC AUC:", roc_auc_score(y_test, y_proba_rf))

# función predicción
# Recibe un JSON
# Devuelve predicción + probabilidad

def predict_flight_delay(input_json, model):
    fecha = pd.to_datetime(input_json["fecha_partida"])     # Convertimos la fecha a datetime



  # Construimos un DataFrame con el mismo esquema del entrenamiento

    df_input = pd.DataFrame([{
        "hour": fecha.hour,
        "distance": input_json["distancia_km"],
        "marketing_airline_network": input_json["aerolinea"],
        "temp_mean": 20.0,
        "precipitation": 0.0,
        "wind_speed": 10.0
    }])

# predicción

    pred = model.predict(df_input)[0]
    proba = model.predict_proba(df_input)[0, 1]

    return {
        "prevision": "Retrasado" if pred == 1 else "Puntual",
        "probabilidad": round(float(proba), 2)
    }

# Simulamos

input_example = {
    "aerolinea": "AA",
    "fecha_partida": "2025-11-10T14:30:00",
    "distancia_km": 850
}

predict_flight_delay(input_example, model)

joblib.dump(model, "MVP_entrenamiento.pkl")

# COMPARACIÓN DE MODELOS: DATASET ORIGINAL VS DATASET AMPLIADO


# En este proyecto se han entrenado los mismos modelos (Regresión
# Logística y Random Forest) sobre dos versiones del dataset:

# 1) Dataset original (reducido):
#    - ~1.600 vuelos
#    - ~19 ciudades
#    - Enero 2018

# 2) Dataset ampliado (final):
#    - ~4.900 vuelos
#    - ~180 ciudades
#    - Mismo periodo temporal (Enero 2018)

# Es importante destacar que NO se ha modificado:
# - el conjunto de variables
# - el pipeline de preprocesado
# - el enfoque MVP
# - el contrato del modelo con el backend

# El único cambio introducido es el aumento de volumen y diversidad
# del dataset, lo que mejora la representatividad del problema real.




# RESULTADO DE LA COMPARACIÓN


# - La regresión logística sigue siendo un baseline válido e interpretable.
# - Con el dataset ampliado, el modelo es más estable y menos dependiente
#   de aeropuertos concretos.
# - Las métricas obtenidas son más realistas y menos optimistas artificialmente.

# El balance de la variable objetivo (delayed) se mantiene similar
# (~18% de vuelos retrasados), por lo que no se introduce sesgo adicional.

# No se detecta data leakage en ninguno de los dos enfoques, ya que
# todas las variables utilizadas están disponibles antes del despegue.


# ELECCIÓN DEL MODELO FINAL: RANDOM FOREST


# Aunque la regresión logística se mantiene como modelo base,
# el Random Forest se elige como modelo final recomendado para producción.

# Justificación:

# 1) Captura relaciones no lineales:
#    - El efecto de la hora, el clima y la distancia no es lineal.
#    - Random Forest captura automáticamente interacciones complejas
#      sin necesidad de ingeniería manual de variables.

# 2) Mejor aprovechamiento del dataset ampliado:
#    - El aumento de ciudades y vuelos beneficia especialmente a
#      modelos basados en árboles.
#    - Cada árbol aprende patrones distintos y el conjunto generaliza mejor.

# 3) Mejor equilibrio entre recall y precision:
#    - Detecta mejor vuelos con riesgo de retraso.
#    - Reduce falsos negativos, que tienen mayor coste operativo.
#
# 4) Mayor robustez:
#    - Menos sensible a ruido y valores extremos en los retrasos.
#    - Comportamiento más estable en escenarios reales.

# 5) Mantiene el enfoque MVP:
#    - No cambia el pipeline.
#    - No cambia el formato de entrada JSON.
#    - No añade complejidad al backend.


# CONCLUSIÓN FINAL


# El modelo ha sido reentrenado con un dataset ampliado que mejora
# la capacidad de generalización sin alterar la estructura del MVP.
# El Random Forest ajustado es el modelo recomendado para producción,
# mientras que la regresión logística se conserva como baseline
# interpretable y de referencia.

# En resumen:
# No se ha cambiado el modelo, se ha mejorado el aprendizaje
# de la realidad operacional.